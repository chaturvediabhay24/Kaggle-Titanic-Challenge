{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Titanic_ANN.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_6-hKliwjyI",
        "colab_type": "code",
        "outputId": "ed70146c-9009-4a48-ee59-447e7f72c8d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTj7hZV1wsYo",
        "colab_type": "code",
        "outputId": "304ffa4b-1dff-4ac7-a9c6-bcedec8067e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd gdrive/My Drive/Datasets/Titanic"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Datasets/Titanic\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ud0TFuWZwuEO",
        "colab_type": "code",
        "outputId": "2f907902-85be-49eb-dff3-38d29830238e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import keras\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_FWyEp6wwQu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv('train.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZR3_H1J-w5pL",
        "colab_type": "code",
        "outputId": "7e47a6d8-b2b6-44fa-d593-6483ce943234",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1200
        }
      },
      "source": [
        "train=train.drop([\"PassengerId\",\"Name\",\"Ticket\",\"Cabin\"],axis=1)\n",
        "train=pd.get_dummies(train, drop_first=True)\n",
        "train.fillna( train.mean(), inplace = True)\n",
        "print(train)\n",
        "y_train=train[\"Survived\"].values\n",
        "x_train=train.drop([\"Survived\"],axis=1).values"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     Survived  Pclass        Age  ...  Sex_male  Embarked_Q  Embarked_S\n",
            "0           0       3  22.000000  ...         1           0           1\n",
            "1           1       1  38.000000  ...         0           0           0\n",
            "2           1       3  26.000000  ...         0           0           1\n",
            "3           1       1  35.000000  ...         0           0           1\n",
            "4           0       3  35.000000  ...         1           0           1\n",
            "5           0       3  29.699118  ...         1           1           0\n",
            "6           0       1  54.000000  ...         1           0           1\n",
            "7           0       3   2.000000  ...         1           0           1\n",
            "8           1       3  27.000000  ...         0           0           1\n",
            "9           1       2  14.000000  ...         0           0           0\n",
            "10          1       3   4.000000  ...         0           0           1\n",
            "11          1       1  58.000000  ...         0           0           1\n",
            "12          0       3  20.000000  ...         1           0           1\n",
            "13          0       3  39.000000  ...         1           0           1\n",
            "14          0       3  14.000000  ...         0           0           1\n",
            "15          1       2  55.000000  ...         0           0           1\n",
            "16          0       3   2.000000  ...         1           1           0\n",
            "17          1       2  29.699118  ...         1           0           1\n",
            "18          0       3  31.000000  ...         0           0           1\n",
            "19          1       3  29.699118  ...         0           0           0\n",
            "20          0       2  35.000000  ...         1           0           1\n",
            "21          1       2  34.000000  ...         1           0           1\n",
            "22          1       3  15.000000  ...         0           1           0\n",
            "23          1       1  28.000000  ...         1           0           1\n",
            "24          0       3   8.000000  ...         0           0           1\n",
            "25          1       3  38.000000  ...         0           0           1\n",
            "26          0       3  29.699118  ...         1           0           0\n",
            "27          0       1  19.000000  ...         1           0           1\n",
            "28          1       3  29.699118  ...         0           1           0\n",
            "29          0       3  29.699118  ...         1           0           1\n",
            "..        ...     ...        ...  ...       ...         ...         ...\n",
            "861         0       2  21.000000  ...         1           0           1\n",
            "862         1       1  48.000000  ...         0           0           1\n",
            "863         0       3  29.699118  ...         0           0           1\n",
            "864         0       2  24.000000  ...         1           0           1\n",
            "865         1       2  42.000000  ...         0           0           1\n",
            "866         1       2  27.000000  ...         0           0           0\n",
            "867         0       1  31.000000  ...         1           0           1\n",
            "868         0       3  29.699118  ...         1           0           1\n",
            "869         1       3   4.000000  ...         1           0           1\n",
            "870         0       3  26.000000  ...         1           0           1\n",
            "871         1       1  47.000000  ...         0           0           1\n",
            "872         0       1  33.000000  ...         1           0           1\n",
            "873         0       3  47.000000  ...         1           0           1\n",
            "874         1       2  28.000000  ...         0           0           0\n",
            "875         1       3  15.000000  ...         0           0           0\n",
            "876         0       3  20.000000  ...         1           0           1\n",
            "877         0       3  19.000000  ...         1           0           1\n",
            "878         0       3  29.699118  ...         1           0           1\n",
            "879         1       1  56.000000  ...         0           0           0\n",
            "880         1       2  25.000000  ...         0           0           1\n",
            "881         0       3  33.000000  ...         1           0           1\n",
            "882         0       3  22.000000  ...         0           0           1\n",
            "883         0       2  28.000000  ...         1           0           1\n",
            "884         0       3  25.000000  ...         1           0           1\n",
            "885         0       3  39.000000  ...         0           1           0\n",
            "886         0       2  27.000000  ...         1           0           1\n",
            "887         1       1  19.000000  ...         0           0           1\n",
            "888         0       3  29.699118  ...         0           0           1\n",
            "889         1       1  26.000000  ...         1           0           0\n",
            "890         0       3  32.000000  ...         1           1           0\n",
            "\n",
            "[891 rows x 9 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CORfLlVOw6If",
        "colab_type": "code",
        "outputId": "abcdd455-22e6-4b19-daa4-0a532080169c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        }
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "onehotencoder = OneHotEncoder(categorical_features = [0])\n",
        "x_train = onehotencoder.fit_transform(x_train).toarray()\n",
        "x_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 1., ..., 1., 0., 1.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 1., ..., 0., 0., 1.],\n",
              "       ...,\n",
              "       [0., 0., 1., ..., 0., 0., 1.],\n",
              "       [1., 0., 0., ..., 1., 0., 0.],\n",
              "       [0., 0., 1., ..., 1., 1., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTzPXQrsw8vv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection  import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size = 0.1, random_state = 0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnw6vsZWw_QX",
        "colab_type": "code",
        "outputId": "bbfa4e70-2aa0-4d66-f848-f1ed68a56dfd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(801, 10) (90, 10) (801,) (90,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8Ekz8k9xBOz",
        "colab_type": "code",
        "outputId": "af14d5c2-5b14-48dc-b336-2387029f92eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        }
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Initialising the ANN\n",
        "classifier = Sequential()\n",
        "\n",
        "# Adding the input layer and the first hidden layer\n",
        "classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu', input_dim = 10))\n",
        "\n",
        "# Adding the second hidden layer\n",
        "classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu'))\n",
        "\n",
        "# Adding the output layer\n",
        "classifier.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=10, units=6, kernel_initializer=\"uniform\")`\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\")`\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFF4dSIWxQKz",
        "colab_type": "code",
        "outputId": "06801942-7ed0-4bfc-9bc1-2d3a89536c91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        }
      },
      "source": [
        "classifier.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_4 (Dense)              (None, 6)                 66        \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 6)                 42        \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 7         \n",
            "=================================================================\n",
            "Total params: 115\n",
            "Trainable params: 115\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pc-cOxDwxS1A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28bdzR0fxYGP",
        "colab_type": "code",
        "outputId": "f83820b8-a5db-479b-e059-a52815c849b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3863
        }
      },
      "source": [
        "\n",
        "classifier.fit(x_train, y_train, batch_size = 5, nb_epoch = 100, validation_data=(x_test,y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 801 samples, validate on 90 samples\n",
            "Epoch 1/100\n",
            "801/801 [==============================] - 1s 1ms/step - loss: 0.6881 - acc: 0.6217 - val_loss: 0.6834 - val_acc: 0.6222\n",
            "Epoch 2/100\n",
            "801/801 [==============================] - 0s 280us/step - loss: 0.6747 - acc: 0.6742 - val_loss: 0.6633 - val_acc: 0.6667\n",
            "Epoch 3/100\n",
            "801/801 [==============================] - 0s 216us/step - loss: 0.6632 - acc: 0.6829 - val_loss: 0.6549 - val_acc: 0.6667\n",
            "Epoch 4/100\n",
            "801/801 [==============================] - 0s 189us/step - loss: 0.6535 - acc: 0.6804 - val_loss: 0.6473 - val_acc: 0.6667\n",
            "Epoch 5/100\n",
            "801/801 [==============================] - 0s 191us/step - loss: 0.6464 - acc: 0.6866 - val_loss: 0.6401 - val_acc: 0.6667\n",
            "Epoch 6/100\n",
            "801/801 [==============================] - 0s 189us/step - loss: 0.6394 - acc: 0.6916 - val_loss: 0.6327 - val_acc: 0.6778\n",
            "Epoch 7/100\n",
            "801/801 [==============================] - 0s 211us/step - loss: 0.6350 - acc: 0.6904 - val_loss: 0.6312 - val_acc: 0.6667\n",
            "Epoch 8/100\n",
            "801/801 [==============================] - 0s 196us/step - loss: 0.6305 - acc: 0.6891 - val_loss: 0.6244 - val_acc: 0.6667\n",
            "Epoch 9/100\n",
            "801/801 [==============================] - 0s 185us/step - loss: 0.6256 - acc: 0.6891 - val_loss: 0.6199 - val_acc: 0.6778\n",
            "Epoch 10/100\n",
            "801/801 [==============================] - 0s 186us/step - loss: 0.6215 - acc: 0.6866 - val_loss: 0.6161 - val_acc: 0.6667\n",
            "Epoch 11/100\n",
            "801/801 [==============================] - 0s 191us/step - loss: 0.6175 - acc: 0.6954 - val_loss: 0.6150 - val_acc: 0.6667\n",
            "Epoch 12/100\n",
            "801/801 [==============================] - 0s 189us/step - loss: 0.6134 - acc: 0.6891 - val_loss: 0.6071 - val_acc: 0.6667\n",
            "Epoch 13/100\n",
            "801/801 [==============================] - 0s 190us/step - loss: 0.6110 - acc: 0.6891 - val_loss: 0.6031 - val_acc: 0.6667\n",
            "Epoch 14/100\n",
            "801/801 [==============================] - 0s 186us/step - loss: 0.6078 - acc: 0.6866 - val_loss: 0.5985 - val_acc: 0.6667\n",
            "Epoch 15/100\n",
            "801/801 [==============================] - 0s 195us/step - loss: 0.6044 - acc: 0.6929 - val_loss: 0.5953 - val_acc: 0.6667\n",
            "Epoch 16/100\n",
            "801/801 [==============================] - 0s 187us/step - loss: 0.5989 - acc: 0.6891 - val_loss: 0.5939 - val_acc: 0.6667\n",
            "Epoch 17/100\n",
            "801/801 [==============================] - 0s 181us/step - loss: 0.5961 - acc: 0.6979 - val_loss: 0.5880 - val_acc: 0.6667\n",
            "Epoch 18/100\n",
            "801/801 [==============================] - 0s 189us/step - loss: 0.5911 - acc: 0.6979 - val_loss: 0.5790 - val_acc: 0.6778\n",
            "Epoch 19/100\n",
            "801/801 [==============================] - 0s 191us/step - loss: 0.5881 - acc: 0.6991 - val_loss: 0.5725 - val_acc: 0.6889\n",
            "Epoch 20/100\n",
            "801/801 [==============================] - 0s 188us/step - loss: 0.5814 - acc: 0.7066 - val_loss: 0.5645 - val_acc: 0.7000\n",
            "Epoch 21/100\n",
            "801/801 [==============================] - 0s 189us/step - loss: 0.5770 - acc: 0.7141 - val_loss: 0.5599 - val_acc: 0.7000\n",
            "Epoch 22/100\n",
            "801/801 [==============================] - 0s 184us/step - loss: 0.5688 - acc: 0.7316 - val_loss: 0.5464 - val_acc: 0.7556\n",
            "Epoch 23/100\n",
            "801/801 [==============================] - 0s 192us/step - loss: 0.5626 - acc: 0.7503 - val_loss: 0.5390 - val_acc: 0.7556\n",
            "Epoch 24/100\n",
            "801/801 [==============================] - 0s 186us/step - loss: 0.5554 - acc: 0.7628 - val_loss: 0.5289 - val_acc: 0.7556\n",
            "Epoch 25/100\n",
            "801/801 [==============================] - 0s 183us/step - loss: 0.5460 - acc: 0.7665 - val_loss: 0.5150 - val_acc: 0.7778\n",
            "Epoch 26/100\n",
            "801/801 [==============================] - 0s 191us/step - loss: 0.5380 - acc: 0.7790 - val_loss: 0.5081 - val_acc: 0.7556\n",
            "Epoch 27/100\n",
            "801/801 [==============================] - 0s 188us/step - loss: 0.5267 - acc: 0.7828 - val_loss: 0.5193 - val_acc: 0.7889\n",
            "Epoch 28/100\n",
            "801/801 [==============================] - 0s 194us/step - loss: 0.5236 - acc: 0.7878 - val_loss: 0.5014 - val_acc: 0.7778\n",
            "Epoch 29/100\n",
            "801/801 [==============================] - 0s 186us/step - loss: 0.5155 - acc: 0.7915 - val_loss: 0.4852 - val_acc: 0.8111\n",
            "Epoch 30/100\n",
            "801/801 [==============================] - 0s 198us/step - loss: 0.5090 - acc: 0.7940 - val_loss: 0.4723 - val_acc: 0.8111\n",
            "Epoch 31/100\n",
            "801/801 [==============================] - 0s 192us/step - loss: 0.4983 - acc: 0.8027 - val_loss: 0.4638 - val_acc: 0.8111\n",
            "Epoch 32/100\n",
            "801/801 [==============================] - 0s 187us/step - loss: 0.4989 - acc: 0.7890 - val_loss: 0.4796 - val_acc: 0.8111\n",
            "Epoch 33/100\n",
            "801/801 [==============================] - 0s 199us/step - loss: 0.4945 - acc: 0.7903 - val_loss: 0.4702 - val_acc: 0.8000\n",
            "Epoch 34/100\n",
            "801/801 [==============================] - 0s 188us/step - loss: 0.4874 - acc: 0.7965 - val_loss: 0.4570 - val_acc: 0.8222\n",
            "Epoch 35/100\n",
            "801/801 [==============================] - 0s 186us/step - loss: 0.4835 - acc: 0.7940 - val_loss: 0.4582 - val_acc: 0.8222\n",
            "Epoch 36/100\n",
            "801/801 [==============================] - 0s 193us/step - loss: 0.4778 - acc: 0.8052 - val_loss: 0.4603 - val_acc: 0.8000\n",
            "Epoch 37/100\n",
            "801/801 [==============================] - 0s 193us/step - loss: 0.4740 - acc: 0.8027 - val_loss: 0.4515 - val_acc: 0.8111\n",
            "Epoch 38/100\n",
            "801/801 [==============================] - 0s 188us/step - loss: 0.4722 - acc: 0.7990 - val_loss: 0.4503 - val_acc: 0.8222\n",
            "Epoch 39/100\n",
            "801/801 [==============================] - 0s 193us/step - loss: 0.4706 - acc: 0.8052 - val_loss: 0.4601 - val_acc: 0.7889\n",
            "Epoch 40/100\n",
            "801/801 [==============================] - 0s 187us/step - loss: 0.4676 - acc: 0.8027 - val_loss: 0.4589 - val_acc: 0.7889\n",
            "Epoch 41/100\n",
            "801/801 [==============================] - 0s 191us/step - loss: 0.4676 - acc: 0.8052 - val_loss: 0.4551 - val_acc: 0.8111\n",
            "Epoch 42/100\n",
            "801/801 [==============================] - 0s 190us/step - loss: 0.4690 - acc: 0.8040 - val_loss: 0.4518 - val_acc: 0.7889\n",
            "Epoch 43/100\n",
            "801/801 [==============================] - 0s 195us/step - loss: 0.4632 - acc: 0.8027 - val_loss: 0.4531 - val_acc: 0.7889\n",
            "Epoch 44/100\n",
            "801/801 [==============================] - 0s 196us/step - loss: 0.4636 - acc: 0.8065 - val_loss: 0.4608 - val_acc: 0.8111\n",
            "Epoch 45/100\n",
            "801/801 [==============================] - 0s 193us/step - loss: 0.4619 - acc: 0.8152 - val_loss: 0.4670 - val_acc: 0.8111\n",
            "Epoch 46/100\n",
            "801/801 [==============================] - 0s 198us/step - loss: 0.4646 - acc: 0.8102 - val_loss: 0.4489 - val_acc: 0.7889\n",
            "Epoch 47/100\n",
            "801/801 [==============================] - 0s 192us/step - loss: 0.4574 - acc: 0.8115 - val_loss: 0.4405 - val_acc: 0.8222\n",
            "Epoch 48/100\n",
            "801/801 [==============================] - 0s 187us/step - loss: 0.4619 - acc: 0.8077 - val_loss: 0.4451 - val_acc: 0.7889\n",
            "Epoch 49/100\n",
            "801/801 [==============================] - 0s 191us/step - loss: 0.4606 - acc: 0.8140 - val_loss: 0.4523 - val_acc: 0.7889\n",
            "Epoch 50/100\n",
            "801/801 [==============================] - 0s 192us/step - loss: 0.4594 - acc: 0.8115 - val_loss: 0.4441 - val_acc: 0.7889\n",
            "Epoch 51/100\n",
            "801/801 [==============================] - 0s 188us/step - loss: 0.4595 - acc: 0.8127 - val_loss: 0.4499 - val_acc: 0.7889\n",
            "Epoch 52/100\n",
            "801/801 [==============================] - 0s 191us/step - loss: 0.4567 - acc: 0.8140 - val_loss: 0.4560 - val_acc: 0.7889\n",
            "Epoch 53/100\n",
            "801/801 [==============================] - 0s 196us/step - loss: 0.4598 - acc: 0.8127 - val_loss: 0.4517 - val_acc: 0.7889\n",
            "Epoch 54/100\n",
            "801/801 [==============================] - 0s 195us/step - loss: 0.4565 - acc: 0.8090 - val_loss: 0.4638 - val_acc: 0.7889\n",
            "Epoch 55/100\n",
            "801/801 [==============================] - 0s 199us/step - loss: 0.4574 - acc: 0.8127 - val_loss: 0.4699 - val_acc: 0.7778\n",
            "Epoch 56/100\n",
            "801/801 [==============================] - 0s 192us/step - loss: 0.4573 - acc: 0.8090 - val_loss: 0.4510 - val_acc: 0.7889\n",
            "Epoch 57/100\n",
            "801/801 [==============================] - 0s 188us/step - loss: 0.4538 - acc: 0.8177 - val_loss: 0.4550 - val_acc: 0.7889\n",
            "Epoch 58/100\n",
            "801/801 [==============================] - 0s 193us/step - loss: 0.4582 - acc: 0.8115 - val_loss: 0.4502 - val_acc: 0.7889\n",
            "Epoch 59/100\n",
            "801/801 [==============================] - 0s 201us/step - loss: 0.4637 - acc: 0.8065 - val_loss: 0.4604 - val_acc: 0.7889\n",
            "Epoch 60/100\n",
            "801/801 [==============================] - 0s 188us/step - loss: 0.4594 - acc: 0.8115 - val_loss: 0.4498 - val_acc: 0.7889\n",
            "Epoch 61/100\n",
            "801/801 [==============================] - 0s 194us/step - loss: 0.4542 - acc: 0.8152 - val_loss: 0.4503 - val_acc: 0.7889\n",
            "Epoch 62/100\n",
            "801/801 [==============================] - 0s 187us/step - loss: 0.4565 - acc: 0.8090 - val_loss: 0.4499 - val_acc: 0.7889\n",
            "Epoch 63/100\n",
            "801/801 [==============================] - 0s 189us/step - loss: 0.4561 - acc: 0.8190 - val_loss: 0.4584 - val_acc: 0.7889\n",
            "Epoch 64/100\n",
            "801/801 [==============================] - 0s 195us/step - loss: 0.4566 - acc: 0.8140 - val_loss: 0.4400 - val_acc: 0.8000\n",
            "Epoch 65/100\n",
            "801/801 [==============================] - 0s 191us/step - loss: 0.4557 - acc: 0.8152 - val_loss: 0.4502 - val_acc: 0.7889\n",
            "Epoch 66/100\n",
            "801/801 [==============================] - 0s 194us/step - loss: 0.4587 - acc: 0.8140 - val_loss: 0.4549 - val_acc: 0.7889\n",
            "Epoch 67/100\n",
            "801/801 [==============================] - 0s 188us/step - loss: 0.4594 - acc: 0.8140 - val_loss: 0.4611 - val_acc: 0.7889\n",
            "Epoch 68/100\n",
            "801/801 [==============================] - 0s 187us/step - loss: 0.4519 - acc: 0.8165 - val_loss: 0.4515 - val_acc: 0.7889\n",
            "Epoch 69/100\n",
            "801/801 [==============================] - 0s 195us/step - loss: 0.4554 - acc: 0.8102 - val_loss: 0.4514 - val_acc: 0.7889\n",
            "Epoch 70/100\n",
            "801/801 [==============================] - 0s 222us/step - loss: 0.4543 - acc: 0.8115 - val_loss: 0.4658 - val_acc: 0.7778\n",
            "Epoch 71/100\n",
            "801/801 [==============================] - 0s 194us/step - loss: 0.4548 - acc: 0.8102 - val_loss: 0.4540 - val_acc: 0.7889\n",
            "Epoch 72/100\n",
            "801/801 [==============================] - 0s 190us/step - loss: 0.4544 - acc: 0.8102 - val_loss: 0.4523 - val_acc: 0.7889\n",
            "Epoch 73/100\n",
            "801/801 [==============================] - 0s 191us/step - loss: 0.4549 - acc: 0.8177 - val_loss: 0.4516 - val_acc: 0.8000\n",
            "Epoch 74/100\n",
            "801/801 [==============================] - 0s 191us/step - loss: 0.4577 - acc: 0.8140 - val_loss: 0.4734 - val_acc: 0.7889\n",
            "Epoch 75/100\n",
            "801/801 [==============================] - 0s 188us/step - loss: 0.4553 - acc: 0.8127 - val_loss: 0.4681 - val_acc: 0.7889\n",
            "Epoch 76/100\n",
            "801/801 [==============================] - 0s 197us/step - loss: 0.4537 - acc: 0.8177 - val_loss: 0.4593 - val_acc: 0.7778\n",
            "Epoch 77/100\n",
            "801/801 [==============================] - 0s 190us/step - loss: 0.4530 - acc: 0.8190 - val_loss: 0.4473 - val_acc: 0.8000\n",
            "Epoch 78/100\n",
            "801/801 [==============================] - 0s 191us/step - loss: 0.4545 - acc: 0.8152 - val_loss: 0.4519 - val_acc: 0.7889\n",
            "Epoch 79/100\n",
            "801/801 [==============================] - 0s 187us/step - loss: 0.4554 - acc: 0.8140 - val_loss: 0.4459 - val_acc: 0.8000\n",
            "Epoch 80/100\n",
            "801/801 [==============================] - 0s 199us/step - loss: 0.4558 - acc: 0.8127 - val_loss: 0.4525 - val_acc: 0.7889\n",
            "Epoch 81/100\n",
            "801/801 [==============================] - 0s 191us/step - loss: 0.4550 - acc: 0.8140 - val_loss: 0.4585 - val_acc: 0.7889\n",
            "Epoch 82/100\n",
            "801/801 [==============================] - 0s 186us/step - loss: 0.4540 - acc: 0.8140 - val_loss: 0.4547 - val_acc: 0.7778\n",
            "Epoch 83/100\n",
            "801/801 [==============================] - 0s 192us/step - loss: 0.4583 - acc: 0.8140 - val_loss: 0.4569 - val_acc: 0.7889\n",
            "Epoch 84/100\n",
            "801/801 [==============================] - 0s 196us/step - loss: 0.4538 - acc: 0.8177 - val_loss: 0.4587 - val_acc: 0.7778\n",
            "Epoch 85/100\n",
            "801/801 [==============================] - 0s 201us/step - loss: 0.4554 - acc: 0.8115 - val_loss: 0.4681 - val_acc: 0.7889\n",
            "Epoch 86/100\n",
            "801/801 [==============================] - 0s 200us/step - loss: 0.4553 - acc: 0.8102 - val_loss: 0.4566 - val_acc: 0.7889\n",
            "Epoch 87/100\n",
            "801/801 [==============================] - 0s 185us/step - loss: 0.4565 - acc: 0.8102 - val_loss: 0.4499 - val_acc: 0.7889\n",
            "Epoch 88/100\n",
            "801/801 [==============================] - 0s 210us/step - loss: 0.4522 - acc: 0.8165 - val_loss: 0.4446 - val_acc: 0.8000\n",
            "Epoch 89/100\n",
            "801/801 [==============================] - 0s 187us/step - loss: 0.4557 - acc: 0.8190 - val_loss: 0.4475 - val_acc: 0.8000\n",
            "Epoch 90/100\n",
            "801/801 [==============================] - 0s 187us/step - loss: 0.4527 - acc: 0.8177 - val_loss: 0.4719 - val_acc: 0.8000\n",
            "Epoch 91/100\n",
            "801/801 [==============================] - 0s 195us/step - loss: 0.4567 - acc: 0.8127 - val_loss: 0.4529 - val_acc: 0.7778\n",
            "Epoch 92/100\n",
            "801/801 [==============================] - 0s 190us/step - loss: 0.4536 - acc: 0.8165 - val_loss: 0.4618 - val_acc: 0.7889\n",
            "Epoch 93/100\n",
            "801/801 [==============================] - 0s 191us/step - loss: 0.4551 - acc: 0.8152 - val_loss: 0.4458 - val_acc: 0.8000\n",
            "Epoch 94/100\n",
            "801/801 [==============================] - 0s 194us/step - loss: 0.4538 - acc: 0.8202 - val_loss: 0.4553 - val_acc: 0.7889\n",
            "Epoch 95/100\n",
            "801/801 [==============================] - 0s 190us/step - loss: 0.4545 - acc: 0.8152 - val_loss: 0.4480 - val_acc: 0.8000\n",
            "Epoch 96/100\n",
            "801/801 [==============================] - 0s 183us/step - loss: 0.4568 - acc: 0.8140 - val_loss: 0.4519 - val_acc: 0.7778\n",
            "Epoch 97/100\n",
            "801/801 [==============================] - 0s 202us/step - loss: 0.4512 - acc: 0.8127 - val_loss: 0.4528 - val_acc: 0.7778\n",
            "Epoch 98/100\n",
            "801/801 [==============================] - 0s 195us/step - loss: 0.4529 - acc: 0.8190 - val_loss: 0.4543 - val_acc: 0.7889\n",
            "Epoch 99/100\n",
            "801/801 [==============================] - 0s 193us/step - loss: 0.4580 - acc: 0.8152 - val_loss: 0.4425 - val_acc: 0.8000\n",
            "Epoch 100/100\n",
            "801/801 [==============================] - 0s 185us/step - loss: 0.4517 - acc: 0.8202 - val_loss: 0.4502 - val_acc: 0.8000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcb8c82dc50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJ3YNQ89yPA4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = pd.read_csv('test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qy7XXZ6uyu94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test=test.drop([\"PassengerId\",\"Name\",\"Ticket\",\"Cabin\"],axis=1)\n",
        "test=pd.get_dummies(test, drop_first=True)\n",
        "test.fillna( test.mean(), inplace = True)\n",
        "x_test=test.values\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3D6EYad_yxig",
        "colab_type": "code",
        "outputId": "9e9295f8-5eb8-4fee-d062-3ad57f77f92d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        }
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "onehotencoder = OneHotEncoder(categorical_features = [0])\n",
        "x_test = onehotencoder.fit_transform(x_test).toarray()\n",
        "x_test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 1., ..., 1., 1., 0.],\n",
              "       [0., 0., 1., ..., 0., 0., 1.],\n",
              "       [0., 1., 0., ..., 1., 1., 0.],\n",
              "       ...,\n",
              "       [0., 0., 1., ..., 1., 0., 1.],\n",
              "       [0., 0., 1., ..., 1., 0., 1.],\n",
              "       [0., 0., 1., ..., 1., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3z-6Bzry0bB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = classifier.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRhkFaDgy2Xs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred=y_pred>0.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWoGpnHvzaQ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred=y_pred.flatten()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqUQJrMuzRFb",
        "colab_type": "code",
        "outputId": "f7040b72-1821-4b37-dbaf-17bdd563f650",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "y_pred.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(418,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Q33r4ecy58M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred=pd.get_dummies(y_pred, drop_first=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDDgyC5hy_hi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}